{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Training a GNN for Graph Classification\n",
        "\n",
        "By the end of this tutorial, you will be able to\n",
        "\n",
        "-  Load a DGL-provided graph classification dataset.\n",
        "-  Understand what *readout* function does.\n",
        "-  Understand how to create and use a minibatch of graphs.\n",
        "-  Build a GNN-based graph classification model.\n",
        "-  Train and evaluate the model on a DGL-provided dataset.\n",
        "\n",
        "(Time estimate: 18 minutes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl\n",
        "from dgl.data.gindt import GINDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview of Graph Classification with GNN\n",
        "\n",
        "Graph classification or regression requires a model to predict certain\n",
        "graph-level properties of a single graph given its node and edge\n",
        "features.  Molecular property prediction is one particular application.\n",
        "\n",
        "This tutorial shows how to train a graph classification model for a\n",
        "small dataset from the paper [How Powerful Are Graph Neural\n",
        "Networks](https://arxiv.org/abs/1810.00826)_.\n",
        "\n",
        "## Loading Data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Generate a synthetic dataset with 10000 graphs, ranging from 10 to 500 nodes.\n",
        "dataset = GINDataset(\"PROTEINS\", self_loop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Graph(num_nodes=42, num_edges=204,\n",
              "       ndata_schemes={'attr': Scheme(shape=(3,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64)}\n",
              "       edata_schemes={}),\n",
              " tensor(0))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset is a set of graphs, each with node features and a single\n",
        "label. One can see the node feature dimensionality and the number of\n",
        "possible graph categories of ``GINDataset`` objects in ``dim_nfeats``\n",
        "and ``gclasses`` attributes.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Node feature dimensionality: 3\n",
            "Number of graph categories: 2\n"
          ]
        }
      ],
      "source": [
        "print(\"Node feature dimensionality:\", dataset.dim_nfeats)\n",
        "print(\"Number of graph categories:\", dataset.gclasses)\n",
        "\n",
        "\n",
        "from dgl.dataloading import GraphDataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining Data Loader\n",
        "\n",
        "A graph classification dataset usually contains two types of elements: a\n",
        "set of graphs, and their graph-level labels. Similar to an image\n",
        "classification task, when the dataset is large enough, we need to train\n",
        "with mini-batches. When you train a model for image classification or\n",
        "language modeling, you will use a ``DataLoader`` to iterate over the\n",
        "dataset. In DGL, you can use the ``GraphDataLoader``.\n",
        "\n",
        "You can also use various dataset samplers provided in\n",
        "[torch.utils.data.sampler](https://pytorch.org/docs/stable/data.html#data-loading-order-and-sampler)_.\n",
        "For example, this tutorial creates a training ``GraphDataLoader`` and\n",
        "test ``GraphDataLoader``, using ``SubsetRandomSampler`` to tell PyTorch\n",
        "to sample from only a subset of the dataset.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "num_examples = len(dataset)\n",
        "num_train = int(num_examples * 0.8)\n",
        "\n",
        "train_sampler = SubsetRandomSampler(torch.arange(num_train))\n",
        "test_sampler = SubsetRandomSampler(torch.arange(num_train, num_examples))\n",
        "\n",
        "train_dataloader = GraphDataLoader(\n",
        "    dataset, sampler=train_sampler, batch_size=5, drop_last=False\n",
        ")\n",
        "test_dataloader = GraphDataLoader(\n",
        "    dataset, sampler=test_sampler, batch_size=5, drop_last=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can try to iterate over the created ``GraphDataLoader`` and see what it\n",
        "gives:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Graph(num_nodes=214, num_edges=924,\n",
              "       ndata_schemes={'attr': Scheme(shape=(3,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64)}\n",
              "       edata_schemes={}),\n",
              " tensor([0, 1, 0, 0, 0])]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "it = iter(train_dataloader)\n",
        "batch = next(it)\n",
        "batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As each element in ``dataset`` has a graph and a label, the\n",
        "``GraphDataLoader`` will return two objects for each iteration. The\n",
        "first element is the batched graph, and the second element is simply a\n",
        "label vector representing the category of each graph in the mini-batch.\n",
        "Next, weâ€™ll talked about the batched graph.\n",
        "\n",
        "## A Batched Graph in DGL\n",
        "\n",
        "In each mini-batch, the sampled graphs are combined into a single bigger\n",
        "batched graph via ``dgl.batch``. The single bigger batched graph merges\n",
        "all original graphs as separately connected components, with the node\n",
        "and edge features concatenated. This bigger graph is also a ``DGLGraph``\n",
        "instance (so you can\n",
        "still treat it as a normal ``DGLGraph`` object as in\n",
        "[here](2_dglgraph.ipynb)_). It however contains the information\n",
        "necessary for recovering the original graphs, such as the number of\n",
        "nodes and edges of each graph element.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of nodes for each graph element in the batch: tensor([43, 13, 96, 22, 40])\n",
            "Number of edges for each graph element in the batch: tensor([215,  57, 370, 100, 182])\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Could not infer dtype of numpy.int64",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mNumber of edges for each graph element in the batch:\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     batched_graph.batch_num_edges(),\n\u001b[32m      9\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Recover the original graph elements from the minibatch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m graphs = \u001b[43mdgl\u001b[49m\u001b[43m.\u001b[49m\u001b[43munbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatched_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mThe original graphs in the minibatch:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(graphs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dgl_env/lib/python3.12/site-packages/dgl/batch.py:425\u001b[39m, in \u001b[36munbatch\u001b[39m\u001b[34m(g, node_split, edge_split)\u001b[39m\n\u001b[32m    418\u001b[39m num_nodes_dict_per = [\n\u001b[32m    419\u001b[39m     {k: split[i] \u001b[38;5;28;01mfor\u001b[39;00m k, split \u001b[38;5;129;01min\u001b[39;00m node_split.items()}\n\u001b[32m    420\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_split)\n\u001b[32m    421\u001b[39m ]\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# Create graphs\u001b[39;00m\n\u001b[32m    424\u001b[39m gs = [\n\u001b[32m--> \u001b[39m\u001b[32m425\u001b[39m     \u001b[43mconvert\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheterograph\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mg\u001b[49m\u001b[43m.\u001b[49m\u001b[43midtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    426\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m edge_dict, num_nodes_dict \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(edge_dict_per, num_nodes_dict_per)\n\u001b[32m    427\u001b[39m ]\n\u001b[32m    429\u001b[39m \u001b[38;5;66;03m# Unbatch node features\u001b[39;00m\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ntype \u001b[38;5;129;01min\u001b[39;00m g.ntypes:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dgl_env/lib/python3.12/site-packages/dgl/convert.py:360\u001b[39m, in \u001b[36mheterograph\u001b[39m\u001b[34m(data_dict, num_nodes_dict, idtype, device)\u001b[39m\n\u001b[32m    348\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m DGLError(\n\u001b[32m    349\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mThe given number of nodes of node type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m must be larger than\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    350\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m the max ID in the data, but got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    351\u001b[39m                     dty, num_nodes_dict[dty], vrange - \u001b[32m1\u001b[39m\n\u001b[32m    352\u001b[39m                 )\n\u001b[32m    353\u001b[39m             )\n\u001b[32m    354\u001b[39m \u001b[38;5;66;03m# Create the graph\u001b[39;00m\n\u001b[32m    355\u001b[39m (\n\u001b[32m    356\u001b[39m     metagraph,\n\u001b[32m    357\u001b[39m     ntypes,\n\u001b[32m    358\u001b[39m     etypes,\n\u001b[32m    359\u001b[39m     relations,\n\u001b[32m--> \u001b[39m\u001b[32m360\u001b[39m ) = \u001b[43mheterograph_index\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_metagraph_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_nodes_dict\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_tensor_dict\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    363\u001b[39m num_nodes_per_type = utils.toindex(\n\u001b[32m    364\u001b[39m     [num_nodes_dict[ntype] \u001b[38;5;28;01mfor\u001b[39;00m ntype \u001b[38;5;129;01min\u001b[39;00m ntypes], \u001b[33m\"\u001b[39m\u001b[33mint64\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    365\u001b[39m )\n\u001b[32m    366\u001b[39m rel_graphs = []\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dgl_env/lib/python3.12/site-packages/dgl/heterograph_index.py:1250\u001b[39m, in \u001b[36mcreate_metagraph_index\u001b[39m\u001b[34m(ntypes, canonical_etypes)\u001b[39m\n\u001b[32m   1248\u001b[39m     etypes.append(etype)\n\u001b[32m   1249\u001b[39m \u001b[38;5;66;03m# metagraph is DGLGraph, currently still using int64 as index dtype\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1250\u001b[39m metagraph = \u001b[43mfrom_coo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mntypes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_edges_src\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_edges_dst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m metagraph, ntypes, etypes, relations\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dgl_env/lib/python3.12/site-packages/dgl/graph_index.py:1081\u001b[39m, in \u001b[36mfrom_coo\u001b[39m\u001b[34m(num_nodes, src, dst, readonly)\u001b[39m\n\u001b[32m   1062\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_coo\u001b[39m(num_nodes, src, dst, readonly):\n\u001b[32m   1063\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Convert from coo arrays.\u001b[39;00m\n\u001b[32m   1064\u001b[39m \n\u001b[32m   1065\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1079\u001b[39m \u001b[33;03m        The graph index.\u001b[39;00m\n\u001b[32m   1080\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1081\u001b[39m     src = \u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtoindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1082\u001b[39m     dst = utils.toindex(dst)\n\u001b[32m   1083\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m readonly:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dgl_env/lib/python3.12/site-packages/dgl/utils/internal.py:304\u001b[39m, in \u001b[36mtoindex\u001b[39m\u001b[34m(data, dtype)\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtoindex\u001b[39m(data, dtype=\u001b[33m\"\u001b[39m\u001b[33mint64\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    288\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Convert the given data to Index object.\u001b[39;00m\n\u001b[32m    289\u001b[39m \n\u001b[32m    290\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    302\u001b[39m \u001b[33;03m    Index\u001b[39;00m\n\u001b[32m    303\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Index) \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dgl_env/lib/python3.12/site-packages/dgl/utils/internal.py:37\u001b[39m, in \u001b[36mIndex.__init__\u001b[39m\u001b[34m(self, data, dtype)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m dtype \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mint32\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mint64\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     36\u001b[39m \u001b[38;5;28mself\u001b[39m.dtype = dtype\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dgl_env/lib/python3.12/site-packages/dgl/utils/internal.py:44\u001b[39m, in \u001b[36mIndex._initialize_data\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28mself\u001b[39m._dgl_tensor_data = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# a dgl ndarray\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;28mself\u001b[39m._slice_data = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# a slice type data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dgl_env/lib/python3.12/site-packages/dgl/utils/internal.py:110\u001b[39m, in \u001b[36mIndex._dispatch\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    105\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DGLError(\n\u001b[32m    106\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIndex data must be 1D int64 vector,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    107\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m but got: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % \u001b[38;5;28mstr\u001b[39m(data)\n\u001b[32m    108\u001b[39m     )\n\u001b[32m    109\u001b[39m \u001b[38;5;28mself\u001b[39m._pydata = data\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m \u001b[38;5;28mself\u001b[39m._user_tensor_data[F.cpu()] = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzerocopy_from_numpy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pydata\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dgl_env/lib/python3.12/site-packages/dgl/backend/pytorch/tensor.py:429\u001b[39m, in \u001b[36mzerocopy_from_numpy\u001b[39m\u001b[34m(np_array)\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mzerocopy_from_numpy\u001b[39m(np_array):\n\u001b[32m--> \u001b[39m\u001b[32m429\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mth\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp_array\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mRuntimeError\u001b[39m: Could not infer dtype of numpy.int64"
          ]
        }
      ],
      "source": [
        "batched_graph, labels = batch\n",
        "print(\n",
        "    \"Number of nodes for each graph element in the batch:\",\n",
        "    batched_graph.batch_num_nodes(),\n",
        ")\n",
        "print(\n",
        "    \"Number of edges for each graph element in the batch:\",\n",
        "    batched_graph.batch_num_edges(),\n",
        ")\n",
        "\n",
        "# Recover the original graph elements from the minibatch\n",
        "graphs = dgl.unbatch(batched_graph)\n",
        "print(\"The original graphs in the minibatch:\")\n",
        "print(graphs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'batched_graph' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mbatched_graph\u001b[49m.ndata[\u001b[33m\"\u001b[39m\u001b[33mattr\u001b[39m\u001b[33m\"\u001b[39m].float()\n",
            "\u001b[31mNameError\u001b[39m: name 'batched_graph' is not defined"
          ]
        }
      ],
      "source": [
        "batched_graph.ndata[\"attr\"].float()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Model\n",
        "\n",
        "This tutorial will build a two-layer [Graph Convolutional Network\n",
        "(GCN)](http://tkipf.github.io/graph-convolutional-networks/)_. Each of\n",
        "its layer computes new node representations by aggregating neighbor\n",
        "information. If you have gone through the\n",
        ":doc:`introduction <1_introduction>`, you will notice two\n",
        "differences:\n",
        "\n",
        "-  Since the task is to predict a single category for the *entire graph*\n",
        "   instead of for every node, you will need to aggregate the\n",
        "   representations of all the nodes and potentially the edges to form a\n",
        "   graph-level representation. Such process is more commonly referred as\n",
        "   a *readout*. A simple choice is to average the node features of a\n",
        "   graph with ``dgl.mean_nodes()``.\n",
        "\n",
        "-  The input graph to the model will be a batched graph yielded by the\n",
        "   ``GraphDataLoader``. The readout functions provided by DGL can handle\n",
        "   batched graphs so that they will return one representation for each\n",
        "   minibatch element.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from dgl.nn import GraphConv\n",
        "\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats, num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GraphConv(in_feats, h_feats)\n",
        "        self.conv2 = GraphConv(h_feats, num_classes)\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        g.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(g, \"h\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Loop\n",
        "\n",
        "The training loop iterates over the training set with the\n",
        "``GraphDataLoader`` object and computes the gradients, just like\n",
        "image classification or language modeling.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.1210762331838565\n"
          ]
        }
      ],
      "source": [
        "# Create the model with given dimensions\n",
        "model = GCN(dataset.dim_nfeats, 16, dataset.gclasses)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(20):\n",
        "    for batched_graph, labels in train_dataloader:\n",
        "        pred = model(batched_graph, batched_graph.ndata[\"attr\"].float())\n",
        "        loss = F.cross_entropy(pred, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "num_correct = 0\n",
        "num_tests = 0\n",
        "for batched_graph, labels in test_dataloader:\n",
        "    pred = model(batched_graph, batched_graph.ndata[\"attr\"].float())\n",
        "    num_correct += (pred.argmax(1) == labels).sum().item()\n",
        "    num_tests += len(labels)\n",
        "\n",
        "print(\"Test accuracy:\", num_correct / num_tests)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Whatâ€™s next\n",
        "\n",
        "-  See [GIN\n",
        "   example](https://github.com/dmlc/dgl/tree/master/examples/pytorch/gin)_\n",
        "   for an end-to-end graph classification model.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Thumbnail credits: DGL\n",
        "# sphinx_gallery_thumbnail_path = '_static/blitz_5_graph_classification.png'"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
